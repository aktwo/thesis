The purpose of this thesis was to test a new, weakly context-dependent multi-armed bandit algorithm that not only balances exploration and exploitation, but also prioritizes novelty to each end-user of the recommendation algorithm. This new algorithm takes advantage of data from all other users, which allows it to scale well BLAH. 

In order to test this new algorithm (UCB1-AKSB), I implemented an anonymous chatroom that I helped build and set it to optimize for maximizing conversation de-anonymizations. After collecting and analyzing conversation and user data, we can draw the following conclusions about the UCB1-AKSB algorithm. 

First, it seems that the algorithm improved some conversation quality metrics but not the metric for which it was calibrated. This is probably due to the fact that the success metric (conversation de-anonymization) was not only dependent on conversation quality (and in some cases might have been negatively correlated) and 2) a binary variable was not fine-grained enough for the size of the data-set that was available. When looking at other metrics of conversation quality, however, it does seem that the algorithm resulted in some noticeable improvement in conversation quality.

Second, the regret analysis

\section{Future Improvements}

Although the performance of the algorithm was mixed 

- Although this is disheartening, there is still room for future testing of this algorithm using other more fine-grained metrics.
- IMPROVEMENTS
	- Need more users, because problem of saturation mentioned above
	- Calibrate on more fine-grained metrics, so that algorithm decisions won't be thrown off so easily
	- Sliding window to allow for fixed set of arms to be re-cycled optimally

For a fixed arm space (i.e. Tigers Anonymous conversation starters), a possible improvement to the UCB1-AKSB algorithm would be to have a moving time-window, so that both users would be guaranteed to see a conversation starter that they haven't seen in at least 5 uses or 5 days (i.e. number of uses or a fixed time length)

FURTHER APPLICATIONS
- A weakly contextual bandit that requires less computation
- Could be used for recommendation algorithms that need to recommend newly generated content (such as blog posts, news websites, etc.) to a relatively homogenous user base
