The purpose of this thesis was to test a new, weakly context-dependent multi-armed bandit algorithm that not only balances exploration and exploitation, but also selects never-before-seen arms for each user pair. By assuming that the reward from each arm was I.I.D, this new algorithm leverages all historical data (regardless of user context) but still allows a certain level of user-specific recommendations. This, in turn, allows it to scale well over a large user base.

In order to test this new algorithm (UCB1-AKSB), I implemented it in Tigers Anonymous and optimized the algorithm to maximize conversation de-anonymizations. After collecting and analyzing conversation and user data, we can draw the following conclusions about the UCB1-AKSB algorithm.

First, the data gathered suggests that some of the key assumptions underpinning the UCB1-AKSB algorithm may not be valid. For example, the two different regimes in the cumulative regret analysis in \autoref{sec:RegretAnalysis} suggest that the distribution of payouts for each bandit arm were not I.I.D as assumed, but rather weakly Markovian. However, for the second regime, the algorithm behaved as expected and produced logarithmic cumulative regret (in line with the canonical UCB1 algorithm). Moreover, the process of conversation de-anonymization may have been more context-dependent than the modified UCB1 algorithm accounted for. 

Second, it seems that the algorithm improved some conversation quality metrics but not the metric for which it was calibrated (although weak signs of improvement can be seen in the proportion of de-anonymizations given the option to de-anonymize). This is probably due to the fact that conversation de-anonymization was not only dependent on the conversation starter (and in some instances might have been independent or negatively correlated) and such a binary variable was not fine-grained enough to measure incremental improvements. However, when looking at other metrics of conversation quality, UCB1-AKSB resulted in noticeable improvement in conversation quality. Moreover, the algorithm seems to have resulted in consistent improvement in per-user performance in all three of the conversation quality metrics defined in this paper (conversation de-anonymization, total conversation length and participation rate).

Finally, the data suggests that, over time, the TA user base became stratified into two categories: power users and new users, with little middle ground. This resulted in increasing volatility in per-user conversation quality metrics (as explained in \autoref{sec:IndividualUserAnalysis}). It also resulted in user saturation, which decreased the overall TA user experience and contributed to the decline in the usage of the site.

In all, it seems that the UCB1-AKSB performed quite well given the violation of some of its fundamental assumptions, its calibration on an imperfect metric and the stratification/saturation of its user base. This leaves substantial room for further testing of this algorithm, and there are some clear recommendations that this thesis can make towards any future research in this area. 

First, any future research would benefit from a larger user base to avoid the problems of user saturation and stratification mentioned in \autoref{sec:IndividualUserAnalysis}. This would make the formation of a `casual-user' class more likely, which would bridge the gap between amateur and power-users, thus improving the user experience and making the chatroom gain more traction with the user base.

Second, the algorithm's performance would likely be improved by using a better measure of conversation quality than a simple binary variable (i.e. the likelihood of de-anonymization). For example, one could create a hybrid metric by assigning a more finely tuned score based on multiple metrics (i.e. 0 for immediate disconnect, 0.3 for a short conversation, 0.7 for a long conversation, and 1 for a de-anonymization). Another option would remove the binary variable (i.e. de-anonymization) altogether, and instead use another metric (such as the participation rate or average conversation length). 

Finally, the algorithm itself could be modified to work more effectively with a static set of arms (or a dynamic set of arms with a slow turnover rate). The current version of the algorithm outlined in \autoref{ch:Methods} simply serves a random arm if both user pairs have already seen the conversation starter. This could be improved by implementing a sliding time window for context-dependency: that is, only use the conversation starters that users $u$ and $v$ haven't seen within the last week or month. This could also be implemented as a sliding number of plays (i.e. only pick from arms that users $u$ and $v$ haven't seen within the last 10 plays).

Not only is there room for future research on the UCB1-AKSB algorithm, but it has broad applications beyond simply selecting quirky conversation starters for an anonymous chatroom. For starters, it is very fast and computationally easy to implement, as opposed to more intensive contextual bandit algorithms such as the one in \citet{chu10}. In applications where context-dependency is only weakly required, such an algorithm would be a great fit. In addition, UCB1-AKSB (or at least some of the principles behind it) can be applied to nearly every bandit recommendation algorithm. In stochastic multi-armed bandit recommendation systems that would benefit from context-dependency, the UCB1-AKSB algorithm provides just the right level of context-dependency by leveraging the assumption that user responses are I.I.D (i.e. the user base is somewhat homogenous, at least in their responses to the arm). It is easy to see this algorithm being applied to recommend news articles, where novelty is important but readers of a given publication (i.e. NYTimes, FT, etc.) are relatively homogenous. In other bandit algorithms that are more heavily context dependent, the arm-filtering mechanism used by UCB1-AKSB could be added on top of the existing bandit mechanism to ensure that users don't see an arm more than once. 

The UCB1-AKSB algorithm fills a gap in the literature: between stochastic multi-armed bandits and context-dependent bandits. It provided a solution to a real-world problem in Tigers Anonymous and it is easy to see how it could be applied with equal success in other contexts. By providing a weakly context-dependent multi-armed bandit algorithm and showing its potential for performance in the real-world, I hope that this thesis will help spur future research into this new class of algorithms.
